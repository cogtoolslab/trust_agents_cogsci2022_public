{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is the analysis script for the Cog Sci 2022 proceedings write-up. \n",
    "\n",
    "All figures in the manuscript, along with stats reported, can be found here.\n",
    "\n",
    "The analysis is organized with figures first and statistics at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import math\n",
    "import socket\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "import matplotlib\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir = os.path.join(proj_dir, 'analysis')\n",
    "data_dir = os.path.join(proj_dir, 'data')\n",
    "plots_dir = os.path.join(analysis_dir, 'figures')\n",
    "\n",
    "TRIAL_CSV = 'physics_continual_learning_trialdata_e2_full.csv'\n",
    "SURVEY_CSV = 'physics_continual_learning_surveydata_e2_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "from ast import literal_eval\n",
    "\n",
    "T = pd.read_csv(os.path.join(data_dir, TRIAL_CSV), \n",
    "                converters={'paddle_tr': literal_eval} # need this to process lists in this column\n",
    "               )\n",
    "S = pd.read_csv(os.path.join(data_dir, SURVEY_CSV))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add manually derived columns (doing this here to show which columns are calculated and not part of experimental logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_intervene(agent, par):\n",
    "    return abs((agent - par + math.pi) % (2*math.pi) - math.pi)\n",
    "\n",
    "def cal_final_angle(agent, par):\n",
    "    if len(par) == 0: return agent\n",
    "    else: return par[-1]\n",
    "    \n",
    "def cal_signed_error(agent, par, gt):\n",
    "    sign_bot = (agent - gt + math.pi) % (2*math.pi) - math.pi\n",
    "    sign_par = (par - gt + math.pi) % (2*math.pi) - math.pi\n",
    "    par_sign_error = abs((par - gt + math.pi) % (2*math.pi) - math.pi) if sign_bot*sign_par > 0 else -abs((par - gt + math.pi) % (2*math.pi) - math.pi)\n",
    "    return par_sign_error\n",
    "\n",
    "def cal_normalized_signed_error(agent, par, gt):\n",
    "    sign_bot = (agent - gt + math.pi) % (2*math.pi) - math.pi\n",
    "    sign_par = (par - gt + math.pi) % (2*math.pi) - math.pi\n",
    "    par_sign_error = sign_par/sign_bot\n",
    "    return par_sign_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T['final_par'] = T.apply(lambda x: cal_final_angle(x['paddle_rho'], list(x['paddle_tr'])), axis=1)\n",
    "T['intervene_dist'] = T.apply(lambda x: cal_intervene(x['paddle_rho'], x['final_par']), axis=1)\n",
    "T['intervene_dist_degrees'] = T['intervene_dist'] * (180 / math.pi)\n",
    "\n",
    "T['bot_error'] = T.apply(lambda x: cal_intervene(x['groundtruthAngle'], x['paddle_rho']), axis=1)\n",
    "T['human_error'] = T.apply(lambda x: cal_intervene(x['groundtruthAngle'], x['final_par']), axis=1)\n",
    "T['human_error_deg'] = T['human_error'] * (180 / math.pi)\n",
    "T['bot_error_deg'] = T['bot_error'] * (180 / math.pi)\n",
    "\n",
    "T['error_diff'] = T['bot_error'] - T['human_error']\n",
    "T['normalized_signed_human_error'] = T.apply(lambda x: cal_normalized_signed_error(x['paddle_rho'], x['final_par'], x['groundtruthAngle']), axis=1)\n",
    "T['signed_human_error'] = T.apply(lambda x: cal_signed_error(x['paddle_rho'], x['final_par'], x['groundtruthAngle']), axis=1)\n",
    "T['signed_human_error_deg'] = T['signed_human_error'] * (180 / math.pi)\n",
    "\n",
    "\n",
    "condition_lookup = {'bad': 'unreliable', 'good': 'reliable',\n",
    "                    'improve': 'improving', 'worsen': 'worsening'}\n",
    "T['condition_str'] = T.agent_cond.map(condition_lookup)\n",
    "\n",
    "# Invert `trustedAgent` column to get `intervention` column\n",
    "T[\"paddleIntervention\"] = ~(T[\"trustedAgent\"]).astype(\"bool\")\n",
    "\n",
    "# Add trial bins (blocks of 12 trials)\n",
    "n_bins = 8\n",
    "n_rounds = 96\n",
    "bin_labs = [str(int(round(a * (n_rounds / n_bins), 0))) for a in range(1, n_bins + 1)]\n",
    "T[\"trial_block\"] = pd.cut(T[\"trialInd\"], bins=8, labels=bin_labs)\n",
    "\n",
    "# Get data for intervention trials only\n",
    "intervention_trials = T[T['paddleIntervention'] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relevant survey columns\n",
    "S['condition_str'] = S.agent_cond.map(condition_lookup)\n",
    "\n",
    "# add in likert responses\n",
    "competence_likert = {\n",
    "    'notCompetent': 0,\n",
    "    'slightlyCompetent': 1,\n",
    "    'moderatelyCompetent': 2,\n",
    "    'veryCompetent': 3\n",
    "}\n",
    "\n",
    "S['competence_likert'] = S.agent_competence.map(competence_likert)\n",
    "\n",
    "\n",
    "\n",
    "to_int = [\n",
    "    'age',\n",
    "    'intervene_rate',\n",
    "    'expected_intervene_rate', \n",
    "    'physics class number'\n",
    "]\n",
    "S[to_int] = S[to_int].astype(int)\n",
    "\n",
    "\n",
    "S = S[~S.agent_cond.isna()]\n",
    "S.loc[:, 'gt_intervene_rate'] = 100 - S.gameID.map(T.groupby('gameID').trustedAgent.mean().to_dict()).copy() * 100\n",
    "S['intervene_acc'] = S.gt_intervene_rate - S.intervene_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure styles, other generic analysis features\n",
    "\n",
    "# source: https://htmlcolorcodes.com/color-chart/\n",
    "palette = {\"unreliable\": \"#E74C3C\", # red\n",
    "          \"reliable\": \"#2980B9\", # blue\n",
    "          \"improving\": \"#7D3C98\", # dark purple\n",
    "          \"worsening\": \"#AF7AC5\" # light purple\n",
    "          }\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Condition summary**\n",
    "\n",
    "Note: additional participant demographics are reported in the statistics section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many subjects per condition?\n",
    "T.groupby(['condition_str'])['gameID'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention rates (Fig. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject level intervention rate by trial block\n",
    "\n",
    "subj_int_rate = T.groupby(\n",
    "    ['gameID', 'trial_block']\n",
    ").agg(\n",
    "    intervention_rate = ('paddleIntervention', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# NB: this is extremely ugly please send help\n",
    "conditions = T.groupby(\n",
    "    ['gameID', 'trial_block']\n",
    ")['condition_str'].unique().reset_index()\n",
    "\n",
    "conditions['cond'] = np.zeros(len(conditions))\n",
    "for i in range(len(conditions)):\n",
    "    conditions.loc[i, 'cond'] = conditions.condition_str[i][0]\n",
    "\n",
    "subj_int_rate['condition_str'] = conditions['cond']\n",
    "\n",
    "subj_int_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: proportion of interventions by trial block\n",
    "\n",
    "plt.figure(figsize=(3,8))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.pointplot(data=subj_int_rate, \n",
    "             ax=ax,\n",
    "             x=\"trial_block\", \n",
    "             y=\"intervention_rate\", \n",
    "             hue=\"condition_str\",\n",
    "             palette=palette\n",
    "            )\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "plt.ylim(0.5, 1.0)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "# Figure settings for write up (modified axes and legend in Adobe Illustrator)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"\")\n",
    "plt.legend().remove()\n",
    "\n",
    "# Figure settings for interpretability: toggle comment to view\n",
    "# ax.set_xlabel(\"Trial index\")\n",
    "# ax.set_ylabel(\"Intervention rate\")\n",
    "# ax.legend(title=\"Condition\",\n",
    "#           loc='center left',\n",
    "#           bbox_to_anchor=(1, 0.3))\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, 'intervention_rate_subj.pdf'), dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error distributions (Fig. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By-subject average signed error\n",
    "subj_error = T.groupby(['gameID', 'condition_str'])['signed_human_error_deg'].agg(\n",
    "    subj_mean = np.mean\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: distribution of signed errors by condition\n",
    "\n",
    "plt.figure(figsize=(3,8))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.kdeplot(data=subj_error,\n",
    "              ax=ax,\n",
    "              x='subj_mean', \n",
    "              hue='condition_str',\n",
    "              bw_adjust=1, # default: 1\n",
    "              linewidth=4,\n",
    "              palette=palette)\n",
    "plt.axvline(x=0, ls='--', c='black', alpha=1)\n",
    "\n",
    "plt.axvline(x=np.mean(subj_error.subj_mean[subj_error.condition_str=='reliable']), \n",
    "            ls='-.', c=palette['reliable'], alpha = 1, linewidth=2)\n",
    "plt.axvline(x=np.mean(subj_error.subj_mean[subj_error.condition_str=='improving']), \n",
    "            ls='-.', c=palette['improving'], alpha = 1, linewidth=2)\n",
    "plt.axvline(x=np.mean(subj_error.subj_mean[subj_error.condition_str=='worsening']), \n",
    "            ls='-.', c=palette['worsening'], alpha = 1, linewidth=2)\n",
    "plt.axvline(x=np.mean(subj_error.subj_mean[subj_error.condition_str=='unreliable']), \n",
    "            ls='-.', c=palette['unreliable'], alpha = 1, linewidth=2)\n",
    "\n",
    "\n",
    "plt.xlim(-5.5, 15.5)\n",
    "ax.xaxis.grid(True)\n",
    "sns.despine(top=True, right=True, left=True)\n",
    "\n",
    "# Figure settings for write up (modified axes and legend in Adobe Illustrator)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_yticklabels([])\n",
    "plt.legend().remove()\n",
    "\n",
    "# Figure settings for interpretability: toggle comment to view\n",
    "# ax.set_xlabel(\"Signed human error (deg.)\")\n",
    "# ax.legend(title=\"Condition\",\n",
    "#           labels = [\"Worsening\", \"Reliable\", \"Improving\", \"Unreliable\"], # NB: this order matters here! \n",
    "#           loc='center left',\n",
    "#           bbox_to_anchor=(1, 0.3))\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, 'error_distributions_individ_combined.pdf'), dpi=300, bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical trials (Fig. 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate critical trials\n",
    "crit = T.loc[T['criticalTrial'] == True, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: average critical trial intervention *rate* by condition\n",
    "\n",
    "plt.figure(figsize=(3,10))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.barplot(data=crit,\n",
    "            ax = ax,\n",
    "            x=\"condition_str\",\n",
    "            y=\"paddleIntervention\",\n",
    "            hue=\"condition_str\",\n",
    "            order=[\"unreliable\", \"improving\", \"worsening\", \"reliable\"],\n",
    "            alpha=0.75,\n",
    "            palette=palette,\n",
    "            dodge=False)\n",
    "\n",
    "plt.axhline(y=1.0, ls='--', c='black')\n",
    "sns.despine(top=True, right=True)\n",
    "ax.yaxis.grid(True)\n",
    "plt.ylim(0.65, 1.05)\n",
    "\n",
    "# Figure settings for write up (modified axes and legend in Adobe Illustrator)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"\")\n",
    "plt.legend().remove()\n",
    "\n",
    "\n",
    "# Figure settings for interpretability: toggle comment to view\n",
    "# ax.set_ylabel(\"Critical trial intervention rate\")\n",
    "# ax.set_xticklabels(['Unreliable', 'Improving', 'Worsening', 'Reliable'])\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, 'critical_trial_intervention_rate.pdf'), \n",
    "            dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: average critical trial intervention *magnitude* by condition\n",
    "\n",
    "plt.figure(figsize=(3,10))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.barplot(data=crit[crit.paddleIntervention==True],\n",
    "            ax = ax,\n",
    "            x=\"condition_str\",\n",
    "            y=\"intervene_dist_degrees\",\n",
    "            hue=\"condition_str\",\n",
    "            alpha=0.75,\n",
    "            order=[\"unreliable\", \"improving\", \"worsening\", \"reliable\"],\n",
    "            palette=palette,\n",
    "            dodge=False)\n",
    "plt.axhline(y=16.04, c=\"k\", ls=\"--\")\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "plt.ylim(10, 21)\n",
    "ax.set_yticks([12, 14, 16, 18, 20])\n",
    "ax.set_yticklabels([\"12\", \"\", \"16\", \"\", \"20\"])\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "# Figure settings for write up (modified axes and legend in Adobe Illustrator)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"\")\n",
    "plt.legend().remove()\n",
    "\n",
    "# Figure settings for interpretability: toggle comment to view\n",
    "# ax.set_title(\"Critical trial interventions\")\n",
    "# ax.set_ylabel(\"Intervention magnitude (deg.)\")\n",
    "# ax.set_xticklabels(['Unreliable', 'Improving', 'Worsening', 'Reliable'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, 'critical_trial_intervention_dist.pdf'), \n",
    "            dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey responses (Fig. 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert survey to long form, modify intervention rate\n",
    "\n",
    "dfs = S.melt(id_vars='condition_str', \n",
    "             value_vars=['expected_intervene_rate', 'intervene_rate'], \n",
    "             value_name='intervene_rate')\n",
    "dfs['intervene_rate'] = dfs['intervene_rate'] / 100 # make formatting consistent with other intervention rate plots\n",
    "\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: average reported intervention rates and expected intervention rates by condition\n",
    "\n",
    "plt.figure(figsize=(3,8))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "g=sns.pointplot(\n",
    "    data=dfs,\n",
    "    ax=ax,\n",
    "    y='intervene_rate', \n",
    "    x='variable', \n",
    "    hue='condition_str',\n",
    "    palette=palette,\n",
    "    order=['intervene_rate', 'expected_intervene_rate'],\n",
    "#     dodge = True # NB: original figure did not have this set but it's probably better...\n",
    ")\n",
    "\n",
    "ax.set_ylim(0.45, 0.95)\n",
    "ax.yaxis.grid(True)\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "# Figure settings for write up (modified axes and legend in Adobe Illustrator)\n",
    "ax.set_xticklabels([\"\", \"\"])\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_title(\"\")\n",
    "plt.legend().remove()\n",
    "\n",
    "# Figure settings for interpretability: toggle comment to view\n",
    "# ax.set_ylabel(\"Intervention rate\")\n",
    "# ax.set_xticklabels([\"Reported (past)\", \"Expected (future)\"])\n",
    "# ax.legend(title=\"Condition\",\n",
    "#           loc='center left',\n",
    "#           bbox_to_anchor=(1, 0.3))\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(plots_dir, 'survey_intervention_expectations.pdf'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Note except where indicated above, all statistical analyses are run in R through the jupyter R interface initialized below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all list columns\n",
    "T_clean = T.drop(['trajectory', 'paddle_tr', 'movePaddleTime', 'response'], axis=1)\n",
    "df = T_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%Rpush df\n",
    "%Rpush S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tidyverse)\n",
    "library(lme4)\n",
    "library(emmeans)\n",
    "\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Demographics\n",
    "print(\"AGE\")\n",
    "print(summary(S$age))\n",
    "print(sd(S$age))\n",
    "\n",
    "print(\"GENDER\")\n",
    "print(table(S$gender))\n",
    "\n",
    "print(\"EDUCATION\")\n",
    "print(table(S$edu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Performance (accuracy, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Percent correct by subject\n",
    "subj_acc = df %>%\n",
    "    group_by(gameID, condition_str) %>%\n",
    "    summarize(subj_mean_acc = sum(correct) / n())\n",
    "\n",
    "print(mean(subj_acc$subj_mean_acc))\n",
    "print(sd(subj_acc$subj_mean_acc))\n",
    "\n",
    "\n",
    "# Percent correct by subject by trial block\n",
    "subj_block_acc = df %>%\n",
    "    group_by(gameID, condition_str, trial_block) %>%\n",
    "    summarize(subj_mean_block_acc = sum(correct) / n())\n",
    "\n",
    "subj_block_acc %>%\n",
    "    group_by(trial_block) %>%\n",
    "    summarize(\n",
    "        mean_acc = mean(subj_mean_block_acc),\n",
    "        sd_acc = sd(subj_mean_block_acc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# subject RMSE\n",
    "\n",
    "subj_rmse = df %>%\n",
    "    group_by(gameID, condition_str) %>%\n",
    "    summarize(subj_mean_rmse = sqrt(mean(human_error_deg^2)),\n",
    "             bot_mean_rmse = sqrt(mean(bot_error_deg^2)))\n",
    "\n",
    "print(mean(subj_rmse$subj_mean_rmse))\n",
    "print(sd(subj_rmse$subj_mean_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# NB: this takes ~10s to run\n",
    "\n",
    "# role of condition and condition * session block interaction on intervention rates\n",
    "intervention_slopes_lme = glmer(\n",
    "    paddleIntervention ~ sessionBlock * condition_str + (1|gameID), \n",
    "    data = df,\n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "m1 = glmer(\n",
    "    paddleIntervention ~ sessionBlock + condition_str + (1|gameID), \n",
    "    data = df,\n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "m0 = glmer(\n",
    "    paddleIntervention ~ sessionBlock + (1|gameID), \n",
    "    data = df,\n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "m00 = glmer(\n",
    "    paddleIntervention ~ (1|gameID), \n",
    "    data = df,\n",
    "    family = \"binomial\"\n",
    ")\n",
    "\n",
    "print(summary(m0)) # Significant slope on block\n",
    "print(anova(intervention_slopes_lme, m1, m0, m00)) # interaction significant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signed error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Signed error comparison\n",
    "\n",
    "subj_signed_error = df %>%\n",
    "    group_by(gameID, condition_str) %>%\n",
    "    summarize(subj_mean_error = mean(signed_human_error_deg))\n",
    "glimpse(subj_signed_error)\n",
    "\n",
    "\n",
    "for(cond in unique(df$condition_str)) {\n",
    "    print(paste0(\"CONDITION: \", cond))\n",
    "    dat = subj_signed_error %>% filter(condition_str == cond)\n",
    "    tst = t.test(x = dat$subj_mean_error, \n",
    "                 mu = 0)\n",
    "    print(tst)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# PREAMBLE: Across *all trials*, is there an interaction between condition and bot error \n",
    "# when predicting intervention distance? i.e. does the amount people compensate for bot error depend on condition?\n",
    "# NOTE: not including slope of trial index here because it's not clear why people intervening *more* over the course\n",
    "# of the experiment should impact the magnitude of their interventions across trials when they *did* intervene.\n",
    "# NOTE also: including the slope actually *improves* our model comparison\n",
    "\n",
    "intervention_trials = df %>%\n",
    "    filter(paddleIntervention == TRUE)\n",
    "\n",
    "m00 = lmer(intervene_dist_degrees ~ condition_str + (1 | gameID),\n",
    "          data = intervention_trials,\n",
    "          REML = F\n",
    "          )\n",
    "\n",
    "m0 = lmer(intervene_dist_degrees ~ condition_str + bot_error_deg + (1 | gameID),\n",
    "          data = intervention_trials,\n",
    "          REML = F\n",
    "         )\n",
    "\n",
    "m1 = lmer(intervene_dist_degrees ~ condition_str * bot_error_deg + (1 | gameID),\n",
    "          data = intervention_trials,\n",
    "          REML = F\n",
    "         )\n",
    "\n",
    "print(anova(m1, m0, m00, test = 'LRT'))\n",
    "print(emmeans(m1, specs = pairwise ~ condition_str)$contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Intervention rate (binary) \n",
    "# Random effects: random slope of trial number within subject, with correlated intercept\n",
    "\n",
    "crit = df %>% filter(criticalTrial == TRUE)\n",
    "\n",
    "m0 = glmer(paddleIntervention ~ (1 + trialInd | gameID), # previous: (1|gameID)\n",
    "           data = crit,\n",
    "           family = \"binomial\",\n",
    "          )\n",
    "\n",
    "m1 = glmer(paddleIntervention ~ condition_str + (1 + trialInd | gameID), # previous: (1|gameID) \n",
    "           data = crit,\n",
    "           family = \"binomial\",\n",
    "          )\n",
    "\n",
    "print(anova(m1, m0, test = 'LRT'))\n",
    "print(emmeans(m1, specs = pairwise ~ condition_str)$contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Intervention distance\n",
    "crit_intervene = crit %>% filter(paddleIntervention == TRUE)\n",
    "\n",
    "m0 = lmer(intervene_dist_degrees ~ (1|gameID),\n",
    "          data = crit_intervene,\n",
    "          REML = F\n",
    "         )\n",
    "m1 = lmer(intervene_dist_degrees ~ condition_str + (1|gameID),\n",
    "          data = crit_intervene,\n",
    "          REML = F\n",
    "         )\n",
    "print(anova(m1, m0, test = 'LRT'))\n",
    "print(emmeans(m1, specs = pairwise ~ condition_str)$contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Interaction between improving and worsening\n",
    "\n",
    "delta_conditions = S\n",
    "\n",
    "delta_conditions_long = delta_conditions %>% \n",
    "    pivot_longer(\n",
    "        cols = c('intervene_rate', 'expected_intervene_rate'),\n",
    "        names_to = 'question',\n",
    "        values_to = 'rating'\n",
    "    )\n",
    "# glimpse(delta_conditions_long)\n",
    "\n",
    "anova_predictions = aov(rating ~ question * condition_str + Error(gameID/question), \n",
    "                        data = delta_conditions_long\n",
    "                       )\n",
    "\n",
    "print(summary(anova_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Follow-up t-tests\n",
    "\n",
    "# Unreliable\n",
    "print(\n",
    "    t.test(\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"unreliable\" & \n",
    "                             delta_conditions_long$question == \"intervene_rate\"],\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"unreliable\" & \n",
    "                             delta_conditions_long$question == \"expected_intervene_rate\"],\n",
    "    paired = T)\n",
    ")\n",
    "\n",
    "\n",
    "# Reliable\n",
    "print(\n",
    "    t.test(\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"reliable\" & \n",
    "                             delta_conditions_long$question == \"intervene_rate\"],\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"reliable\" & \n",
    "                             delta_conditions_long$question == \"expected_intervene_rate\"],\n",
    "    paired = T)\n",
    ")\n",
    "\n",
    "# Worsening\n",
    "print(\n",
    "    t.test(\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"worsening\" & \n",
    "                             delta_conditions_long$question == \"intervene_rate\"],\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"worsening\" & \n",
    "                             delta_conditions_long$question == \"expected_intervene_rate\"],\n",
    "    paired = T)\n",
    ")\n",
    "\n",
    "# Improving\n",
    "print(\n",
    "    t.test(\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"improving\" & \n",
    "                             delta_conditions_long$question == \"intervene_rate\"],\n",
    "    delta_conditions_long$rating[delta_conditions_long$condition_str == \"improving\" & \n",
    "                             delta_conditions_long$question == \"expected_intervene_rate\"],\n",
    "    paired = T)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Relationship between predicted intervention rates and reported trust\n",
    "\n",
    "cor.test(S$expected_intervene_rate, S$competence_likert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
